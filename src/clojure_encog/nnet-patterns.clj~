(ns clojure-encog.nnets

(:import 
(org.encog.neural.pattern 
       FeedForwardPattern ADALINEPattern ART1Pattern BAMPattern
       BoltzmannPattern CPNPattern ElmanPattern HopfieldPattern PatternError
       JordanPattern SOMPattern PNNPattern SVMPattern RadialBasisPattern)
       
(org.encog.engine.network.activation 
       ActivationTANH ActivationSigmoid ActivationGaussian ActivationBiPolar 
       ActivationLinear  ActivationLOG ActivationRamp ActivationSoftMax 
       ActivationSIN ActivationBipolarSteepenedSigmoid ActivationClippedLinear
       ActivationCompetitive ActivationElliott ActivationElliottSymmetric ActivationSteepenedSigmoid)
       
(org.encog.neural.networks BasicNetwork)       
   
   
   
   ))





 (defn make-pattern  
 "Constructs a neural base pattern from which we can generate 
 a concrete network effortlessly (see make-network for details).
 Options include:
 -------------------------------------------------------------
 :feed-forward  :adaline  :art1  :bam  :boltzman      
 :jordan        :elman    :svm   :rbf  :hopfield    
 :som           :pnn      :cpn                  
 -------------------------------------------------------------
 Returns an object that implements NeuralNetworkPattern."
  [model]
  (condp = model
       :feed-forward (FeedForwardPattern.)
       :adaline      (ADALINEPattern.)
       :art1         (ART1Pattern.)
       :bam          (BAMPattern.)
       :boltzman     (BoltzmannPattern.)
       :cpn          (CPNPattern.)
       :elman        (ElmanPattern.)
       :hopfield     (HopfieldPattern.)
       :jordan       (JordanPattern.)
       :som          (SOMPattern.)
       :pnn          (PNNPattern.)
       :svm          (SVMPattern.)
       :rbf          (RadialBasisPattern.)
 :else (throw (IllegalArgumentException. "Unsupported neural-pattern!"))) )

;;usage: 
;;(make-pattern :feed-forward)
;;(make-pattern :svm)

 (defn make-activationF  
 "Constructs an activation-function to be used by the layers.
  Expects a keyword-based argument. Options include:
  --------------------------------------------------
  :tanh     :sigmoid   :gaussian    :bipolar  
  :linear   :log       :ramp        :sin
  :elliot   :soft-max  :competitive :bipolar-steepend
  :elliot-symmetric :clipped-linear :steepened-sigmoid
  ---------------------------------------------------
  Returns an ActivationFunction object." 
 [fun]
 (condp = fun 
      :tanh     (ActivationTANH.)
      :sigmoid  (ActivationSigmoid.)
      :gaussian (ActivationGaussian.)
      :bipolar  (ActivationBiPolar.)
      :linear   (ActivationLinear.) 
      :log      (ActivationLOG.)
      :ramp     (ActivationRamp.)
      :sin      (ActivationSIN.)
      :soft-max (ActivationSoftMax.)
      :bipolar-steepend (ActivationBipolarSteepenedSigmoid.)
      :clipped-linear   (ActivationClippedLinear.)
      :competitive      (ActivationCompetitive.)
      :elliot           (ActivationElliott.)
      :elliot-symmetric (ActivationElliottSymmetric.)
      :steepened-sigmoid (ActivationSteepenedSigmoid.)))

;;usage: (make-activationF :tanh)
;;       (make-activationF :linear)

 (defn make-network
 "Constructs a neural-network given some layers, an activation and a neural pattern.
  'layers' has to be map with 3 keys {:input x :output y :hidden [k j & more]} where :hidden holds a vector
  whose size is the number of desirable hidden layers. The layers are added sequentially to
  the input layer so first hhidden layer will have k neurons, the second j neurons and so forth.
  See example usage below.
  Returns the complete neural-network object with randomized weights.
  
  e.g: 
  (make-network {:input 32 
                 :output 1 
                 :hidden [40, 10, 5]}   ;3 hidden layers (first has 40 neurons, second 10, third 5)
               (make-activationF :tanh) ;hyperbolic tangent for activation function
               (make-pattern     :feed-forward))"
 [layers activation p] 
 (let [pattern p]
      (do  (.setInputNeurons pattern  (layers :input))
           (.setOutputNeurons pattern (layers :output))
      (try (.setActivationFunction pattern activation) 
      (catch PatternError ex (println ex))))
 (dotimes [i (count (layers :hidden))] 
 (.addHiddenLayer pattern ((layers :hidden) i)))
 (.generate pattern)))  ;;finally, return the complete network object


;;usage:
(comment (make-network {:input 32
                        :output 1
                        :hidden [40, 10]} ;2 hidden layers
               (make-activationF :tanh) 
               (make-pattern :feed-forward))  )













(comment
(defmulti make-network 
"Constructs a neural-network given a neural pattern.
 Returns the complete neural-network object."
class)


(defmethod make-network FeedForwardPattern
[p] 
(let [pattern p]
          (.setInputNeurons pattern input-neurons)
          (.setOutputNeurons pattern output-neurons)
          (.setActivationFunction pattern activation)
 (dotimes [i (count hidden-layers-map)] 
 (.addHiddenLayer pattern (get hidden-layers-map (keyword (str i)))))
 (.generate pattern)))  )
 
 






























